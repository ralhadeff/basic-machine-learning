{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data used is paragraphs (lines) from one of my papers, after removing all the headers, figures, and references.<br>\n",
    "https://doi.org/10.1073/pnas.1810316115"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open file\n",
    "raw_data = open(\"sample.txt\", \"r\")\n",
    "data = []\n",
    "# read line by line\n",
    "for l in raw_data:\n",
    "    # split paragraph into discrete sentences\n",
    "    sentences = re.split('\\. |\\? |! ',l)\n",
    "    for s in sentences:\n",
    "        if (s[0].islower()):\n",
    "            # this is a wrong split (i.e. / e.g. etc), add to the end of the previous sentence\n",
    "            if (len(data)>0):\n",
    "                s = data.pop()+' '+s\n",
    "        # make lower case and remove all punctuation (except hyphen) and numbers\n",
    "        s = s.lower()\n",
    "        s = s.translate(str.maketrans('','',(string.punctuation+string.digits+'\\n'+'\\t').replace('-','')))\n",
    "        # add to data sentences that have at least 2 words\n",
    "        if (len(s.split())>1):\n",
    "            data.append(s)\n",
    "\n",
    "# note - there are some specific issues with Fig. S# and words that are always capitalized, such as ATP\n",
    "# but overall, this should be good enough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make list of unique words\n",
    "tokens = set()\n",
    "for s in data:\n",
    "    tokens.update(s.split())\n",
    "# transform to list\n",
    "tokens = list(tokens)\n",
    "# generate dictionary to convert tokens to ID's\n",
    "token_to_id = {token:i for (i,token) in enumerate(tokens)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate pairs of target,context\n",
    "window = 3\n",
    "pairs = []\n",
    "for l in data:\n",
    "    s = l.split()\n",
    "    for i in range(len(s)):\n",
    "        target = s[i]\n",
    "        for j in range(i-window,i+window+1):\n",
    "            if (j>=0 and j!=i and j<len(s)):\n",
    "                pairs.append((token_to_id[target],token_to_id[s[j]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1190"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform to one-hot-encoded\n",
    "n = len(tokens)\n",
    "n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the result of performing matrix multiplication is essentially the same as selecting the ith row of the word embedding matrix. We can save lots of computational time by simply selecting the row associating with the input word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: You might have been wondering why there is a factor of 1/m in dL_dW while not in dL_dword_vec . In each pass, we process m training examples together. For weights in the dense layer, we would like to update them with the average of the m gradient descents. For weights in the word vector, each vector has its own weights which lead to its own gradient descent so we do not need to aggregate the m gradient descents while we updating."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
