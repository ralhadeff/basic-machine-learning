{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.genfromtxt('train.csv', delimiter=',',skip_header=1)\n",
    "# normalize X\n",
    "X = (data[:,1:]/255).reshape(-1,28,28,1)\n",
    "# one hot encode y\n",
    "y = np.zeros(shape=(len(X),10),dtype=int)\n",
    "y[np.arange(len(data)),data[:,0].astype(int)] = 1\n",
    "# subsample X (for faster training)\n",
    "X_copy = X.copy()\n",
    "mask = np.random.choice(range(len(X)),size=2000)\n",
    "X = X[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Convolution2D, LeakyReLU, BatchNormalization, Flatten, Concatenate\n",
    "from keras.layers import Dense, Input, Reshape, ReLU, Conv2DTranspose, Activation, Reshape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_models():\n",
    "    '''Generate keras models for a functional DCGAN'''\n",
    "    # discriminator\n",
    "    input_layer = Input(shape = X[0].shape)\n",
    "    x = Convolution2D(filters=32, kernel_size=(5, 5), strides=(2, 2), padding='same')(input_layer)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    x = Convolution2D(filters=64, kernel_size=(5, 5), strides=(2, 2), padding='same')(x)\n",
    "    x = BatchNormalization(momentum=0.5)(x)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    x = Convolution2D(filters=128, kernel_size=(5, 5), strides=(2, 2), padding='same')(x)\n",
    "    x = BatchNormalization(momentum=0.5)(x)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    x = Flatten()(x)\n",
    "    input_label = Input(shape=(1,1,10))\n",
    "    il = Reshape((10,))(input_label)\n",
    "    x = Concatenate()([x, il])\n",
    "    output = (Dense(1,activation='sigmoid'))(x)\n",
    "\n",
    "    discriminator = Model(inputs=[input_layer,input_label],outputs=output)\n",
    "    discriminator.compile(optimizer='adam',loss='binary_crossentropy')\n",
    "\n",
    "    # generator\n",
    "    input_layer = Input(shape=(1,1,100))\n",
    "    input_label = Input(shape=(1,1,10))\n",
    "    x = Concatenate()([input_layer, input_label])\n",
    "    x = Dense(2048)(x)\n",
    "    x = Reshape(target_shape=(4, 4, 128))(x)\n",
    "    x = BatchNormalization(momentum=0.5)(x)\n",
    "    x = ReLU()(x)\n",
    "    x = Conv2DTranspose(filters=64,kernel_size=(5, 5),strides=(2, 2),padding='same',output_padding=(0,0))(x)\n",
    "    x = BatchNormalization(momentum=0.5)(x)\n",
    "    x = ReLU()(x)\n",
    "    x = Conv2DTranspose(filters=32, kernel_size=(5, 5), strides=(2, 2), padding='same')(x)\n",
    "    x = BatchNormalization(momentum=0.5)(x)\n",
    "    x = ReLU()(x)\n",
    "    x = Conv2DTranspose(filters=1, kernel_size=(5, 5), strides=(2, 2), padding='same')(x)\n",
    "    x = BatchNormalization(momentum=0.5)(x)\n",
    "    output = Activation('tanh')(x)\n",
    "\n",
    "    generator = Model(inputs = [input_layer,input_label],outputs = output)\n",
    "    generator.compile(optimizer='adam',loss='binary_crossentropy')\n",
    "\n",
    "    input_layer = Input((1,1,100))\n",
    "    input_label = Input((1,1,10))\n",
    "    image = generator([input_layer, input_label])\n",
    "    discriminator.trainable = False\n",
    "    verdict = discriminator([image, input_label])\n",
    "    gan = Model(inputs=[input_layer, input_label], outputs=verdict)\n",
    "    gan.compile(optimizer='adam',loss='binary_crossentropy')\n",
    "    \n",
    "    return discriminator, generator, gan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training models with labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/raphael/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/raphael/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "# initialize models\n",
    "discriminator, generator, gan = build_models()\n",
    "\n",
    "# setup parameters\n",
    "epochs = 200\n",
    "print_fq = 20\n",
    "batch_size = 100\n",
    "generator_ratio = 2\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    if ((epoch+1)%print_fq==0):\n",
    "        print('Epoch: ',epoch+1)\n",
    "    for batch in range(len(X)//batch_size):\n",
    "        # normalize data to -1, 1 (works better that way, also in line with tanh output of generator)\n",
    "        x_b = X[batch*batch_size:(batch+1)*batch_size]*2-1\n",
    "        y_b = y[batch*batch_size:(batch+1)*batch_size]\n",
    "        # randomly generate latent values\n",
    "        z = np.random.normal(size=((len(x_b),)+(1,1,100)))\n",
    "        images = generator.predict([z,y_b.reshape((-1,1,1,10))])\n",
    "        # add noise to images\n",
    "        x_b = x_b + np.random.normal(scale=0.2,size=x_b.shape)\n",
    "        x_b = np.clip(x_b,0,1)\n",
    "        images = images + np.random.normal(scale=0.2,size=images.shape)\n",
    "        images = np.clip(images,0,1)\n",
    "        # generate labels for discriminator\n",
    "        real = np.ones(len(x_b)) - np.random.random(size=len(x_b))*0.2\n",
    "        fake = np.zeros(len(x_b)) + np.random.random(size=len(x_b))*0.2\n",
    "        \n",
    "        # train discriminator once\n",
    "        discriminator.trainable = True\n",
    "        discriminator.train_on_batch([x_b,y_b.reshape((-1,1,1,10))],real)\n",
    "        discriminator.train_on_batch([images,y_b.reshape((-1,1,1,10))],fake)\n",
    "        \n",
    "        # train generator n times\n",
    "        for i in range(generator_ratio):\n",
    "            discriminator.trainable = False\n",
    "            # generate new images\n",
    "            z = np.random.normal(size=((len(x_b),)+(1,1,100)))\n",
    "            # discriminator should be fooled into accepting those images\n",
    "            fool = np.ones(len(x_b)) - np.random.random(size=len(x_b))*0.2\n",
    "            gan.train_on_batch([z,y_b.reshape((-1,1,1,10))],fool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.random.normal(size=(5,1,1,100))\n",
    "\n",
    "im = generator.predict(z)\n",
    "\n",
    "fig, ax = plt.subplots(ncols=5,figsize=(16,6))\n",
    "for i in range(5):\n",
    "    ax[i].imshow(im[i].reshape(28,28),cmap='gray')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
