{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement learning\n",
    "### Snake - dynamic programming \n",
    "**Reference code** that cannot be executed (some functions called below are not implemented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snake import Game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all state space\n",
    "S = []\n",
    "for a in range(2):\n",
    "    for b in range(2):\n",
    "        for c in range(2):\n",
    "            for d in range(2):\n",
    "                for e in range(-1,2):\n",
    "                    for f in range(-1,2):\n",
    "                        S.append((a,b,c,d,e,f))\n",
    "len(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# game\n",
    "game = Game()\n",
    "\n",
    "# initialize values\n",
    "V = {}\n",
    "for s in S:\n",
    "    V[s] = 0\n",
    "\n",
    "# discount factor\n",
    "g = 0.9\n",
    "\n",
    "# iterative policy evaluation\n",
    "# iterate over states using a policy (determined by p(s,a))\n",
    "while(True):\n",
    "    delta = 0\n",
    "    for s in S:\n",
    "        old_v = V[s]\n",
    "        game.set_state(s)\n",
    "        for a in game.available_actions():\n",
    "            r = game.play(a)\n",
    "            V[s] += p(s,a)*(r + g * V[game.get_state()])\n",
    "        delta = max(delta,abs(V[s]-old_v))\n",
    "    if delta<threshold:\n",
    "        break   \n",
    "\n",
    "# this is not a reasonable solution for snake because the state cannot normally be set\n",
    "# this code is only kept for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# policy iteration\n",
    "\n",
    "# all possible actions\n",
    "actions = [0,1,2,3]\n",
    "\n",
    "# initialize a random policy\n",
    "policy = {}\n",
    "for s in S:\n",
    "    policy{s} = np.random.choice(actions)\n",
    "    \n",
    "while(True):\n",
    "    iterative_policy_evaluation(policy) # same as above, but without p(s,a), since the policy is determined\n",
    "    # policy improvement\n",
    "    converged = True\n",
    "    for s in S:\n",
    "        old_a = policy[s]\n",
    "        best_v = float('-inf')\n",
    "        best_a = None\n",
    "        for a in actions:\n",
    "            # check which action from this state is best\n",
    "            game.set_state(s)\n",
    "            r = game.play(a)\n",
    "            v = r + g*V[game.get_state()]\n",
    "            if (v>best_v):\n",
    "                best_v = v\n",
    "                best_a = a\n",
    "        # if current policy is not the best\n",
    "        if (best_a != policy[s]):\n",
    "            # update policy\n",
    "            converged = False\n",
    "            policy[s] = best_a\n",
    "    if (converged):\n",
    "        # done\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
