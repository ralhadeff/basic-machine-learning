{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement learning\n",
    "### Snake - Monte Carlo\n",
    "Play games and iteratively improve the state values and corresponding policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snake import Game\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from matplotlib import animation\n",
    "from IPython.display import HTML, Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified dictionary that incorporates random defaults and epsilon greedy\n",
    "class Policy(dict):\n",
    "    \n",
    "    import random\n",
    "    \n",
    "    def __init__(self,actions,epsilon=0.1):\n",
    "        '''\n",
    "        A policy with built in epsilon greedy and a uniform random choice for non initialized keys \n",
    "        actions - list of all possible actions\n",
    "        epsilon - chance for explore\n",
    "        '''\n",
    "        self.actions = actions\n",
    "        self.eps = epsilon\n",
    "        super().__init__(self)\n",
    "        \n",
    "    def __getitem__(self, key):\n",
    "        c = random.random()\n",
    "        if (c<self.eps or key not in self):\n",
    "            return self.actions[random.randint(0,len(self.actions)-1)]\n",
    "        else:\n",
    "            return super().__getitem__(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# game parameters\n",
    "grid = 8\n",
    "s_size = 3\n",
    "# start game\n",
    "game = Game(grid, s_size)\n",
    "game.reset()\n",
    "\n",
    "# discount factor\n",
    "g = 0.9\n",
    "\n",
    "# initialize policy\n",
    "policy = Policy([0,1,2,3])\n",
    "\n",
    "# dummy state for a lost game\n",
    "LOSS = tuple(np.ones(6)*-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3 0\n",
      "1000 10 1\n",
      "2000 2 0\n",
      "3000 11 1\n",
      "4000 10 1\n",
      "5000 3 0\n",
      "6000 15 2\n",
      "7000 39 6\n",
      "8000 74 8\n",
      "9000 54 7\n"
     ]
    }
   ],
   "source": [
    "# aggregated values for states and actions\n",
    "agg = {}\n",
    "# calculated Q values\n",
    "Q = {}\n",
    "\n",
    "# run MC loop\n",
    "for i in range(10000):\n",
    "    # play one episode\n",
    "    # game log\n",
    "    history = []\n",
    "    r = 0\n",
    "    score = 0\n",
    "    turns = 0\n",
    "    while (True):\n",
    "        # count turns (success in terms of not dying)\n",
    "        turns+=1\n",
    "        # count score\n",
    "        if (game.score>score):\n",
    "            score = game.score\n",
    "        # get current state\n",
    "        s = tuple(game.get_state())\n",
    "        # choose action\n",
    "        a = policy[s]\n",
    "        # update history before moving to the next state\n",
    "        history.append((s,r,a))\n",
    "        # apply action\n",
    "        game.snake.d = a\n",
    "        # run one game step, get reward and check if episode is finished\n",
    "        r,e = game.iterate() \n",
    "        if (e==-1):\n",
    "            # game is lost, add final dummy state\n",
    "            history.append((LOSS,r,0))\n",
    "            # start a new episode\n",
    "            break\n",
    "        if (e==1):\n",
    "            # eat apple, add modified state\n",
    "            eat = np.array(s)\n",
    "            eat[-2:] = 0\n",
    "            history.append((tuple(eat),r,0))\n",
    "            r = 0\n",
    "    # update Q returns (values for this episode)\n",
    "    q_values = []\n",
    "    value = 0\n",
    "    for s,r,a in reversed(history):\n",
    "        q_values.append((s,a,value))\n",
    "        # update value\n",
    "        value = r + g*value\n",
    "    q_values.reverse()\n",
    "    # update aggregated q_values\n",
    "    for s,a,v in q_values:\n",
    "        # aggregated values\n",
    "        if ((s,a) in agg):\n",
    "            agg[(s,a)].append(v)\n",
    "        else:\n",
    "            agg[(s,a)] = [v]\n",
    "        # average\n",
    "        if (s in Q):\n",
    "            Q[s][a] = np.mean(agg[(s,a)])\n",
    "        else:\n",
    "            Q[s] = {}\n",
    "            Q[s][a] = np.mean(agg[(s,a)])\n",
    "    # update policy\n",
    "    for s in Q:\n",
    "        aq = ([i for i in Q[s].items()])\n",
    "        a = np.argmax([i[1] for i in aq])\n",
    "        policy[s] = [i[0] for i in aq][a]\n",
    "    # print progress\n",
    "    if (i%1000==0):\n",
    "        print(i,turns,score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the policy without epsilon greedy\n",
    "p = dict(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# render a game animation\n",
    "fig, ax = plt.subplots()\n",
    "image = ax.imshow(game.board)\n",
    "\n",
    "g = Game(grid, s_size)\n",
    "g.reset()\n",
    "\n",
    "def init():\n",
    "    image.set_data(g.board)\n",
    "    return (image,)\n",
    "\n",
    "def animate(i):\n",
    "    s = g.get_state()\n",
    "    a = p[tuple(s)]\n",
    "    g.snake.d = a\n",
    "    g.iterate() \n",
    "    g.draw()\n",
    "    image.set_data(g.board)\n",
    "    return (image,)\n",
    "\n",
    "anim = animation.FuncAnimation(fig, animate, init_func=init,\n",
    "                               frames=300, interval=120, \n",
    "                               blit=True)\n",
    "\n",
    "anim.save('./animations/monte_carlo.gif', writer='imagemagick', fps=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"./animations/monte_carlo.gif\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url='./animations/monte_carlo.gif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
