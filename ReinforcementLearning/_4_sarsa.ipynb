{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement learning\n",
    "### Snake - Temporal difference\n",
    "SARSA algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snake import Game\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from matplotlib import animation\n",
    "from IPython.display import HTML, Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified dictionary that incorporates random defaults and epsilon greedy\n",
    "class Policy(dict):\n",
    "    \n",
    "    import random\n",
    "    \n",
    "    def __init__(self,actions,epsilon=0.1):\n",
    "        '''\n",
    "        A policy with built in epsilon greedy and a uniform random choice for non initialized keys \n",
    "        actions - list of all possible actions\n",
    "        epsilon - chance for explore\n",
    "        '''\n",
    "        self.actions = actions\n",
    "        self.eps = epsilon\n",
    "        super().__init__(self)\n",
    "        \n",
    "    def __getitem__(self, key):\n",
    "        c = random.random()\n",
    "        if (c<self.eps or key not in self):\n",
    "            return self.actions[random.randint(0,len(self.actions)-1)]\n",
    "        else:\n",
    "            return super().__getitem__(key)\n",
    "        \n",
    "    def update_with_Q(self,s,qs):\n",
    "        '''Update policy for a state given the Q values for this state and all available actions'''\n",
    "        # update policy for this state\n",
    "        a = np.argmax([i[1] for i in qs.items()])\n",
    "        self[s] = [i[0] for i in qs.items()][a]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# game parameters\n",
    "grid = 8\n",
    "s_size = 3\n",
    "# start game\n",
    "game = Game(grid, s_size)\n",
    "game.reset()\n",
    "\n",
    "# discount factor\n",
    "g = 0.9\n",
    "# learning rate\n",
    "learning_rate = 0.1\n",
    "\n",
    "# initialize policy\n",
    "policy = Policy([0,1,2,3])\n",
    "\n",
    "# dummy state for a lost game\n",
    "LOSS = tuple(np.ones(6)*-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2 0\n",
      "1000 54 6\n",
      "2000 24 5\n",
      "3000 54 9\n",
      "4000 11 0\n",
      "5000 15 2\n",
      "6000 2 0\n",
      "7000 5 1\n",
      "8000 43 5\n",
      "9000 9 1\n"
     ]
    }
   ],
   "source": [
    "# Q values\n",
    "Q = {}\n",
    "Q[LOSS] = {}\n",
    "Q[LOSS][0] = 0\n",
    "# state/action counts (for decaying learning rate)\n",
    "counts = {}\n",
    "\n",
    "# run MC loop\n",
    "for i in range(10000):\n",
    "    # reset some variables\n",
    "    s = tuple(game.get_state())\n",
    "    r = 0\n",
    "    a = policy[s]\n",
    "    score = 0\n",
    "    turns = 0\n",
    "    # play one episode\n",
    "    while (True):\n",
    "        # count turns (success in terms of not dying)\n",
    "        turns+=1\n",
    "        # count score\n",
    "        if (game.score>score):\n",
    "            score = game.score\n",
    "        # apply action\n",
    "        game.snake.d = a\n",
    "        # run one game step, get reward and check if episode is finished\n",
    "        r,e = game.iterate()\n",
    "        # decaying learning rate\n",
    "        if (s not in counts):\n",
    "            counts[s] = {}\n",
    "        if (a not in counts[s]):\n",
    "            counts[s][a] = 0\n",
    "        counts[s][a]+=1\n",
    "        lr = learning_rate/(1+counts[s][a]//10)\n",
    "        # add default Q if missing\n",
    "        if (s not in Q):\n",
    "            Q[s] = {}\n",
    "        if (a not in Q[s]):\n",
    "            Q[s][a] = 0\n",
    "        # treat specific cases\n",
    "        if (e==-1):\n",
    "            # game is lost, update with final dummy state\n",
    "            Q[s][a] = Q[s][a] + lr*(r + g*Q[LOSS][0] - Q[s][a])\n",
    "            policy.update_with_Q(s,Q[s])\n",
    "            # start a new episode\n",
    "            break\n",
    "        elif (e==1):\n",
    "            # eat apple, update modified state\n",
    "            eat = np.array(s)\n",
    "            eat[-2:] = 0\n",
    "            if (tuple(eat) not in Q):\n",
    "                Q[tuple(eat)] = {}\n",
    "                Q[tuple(eat)][0] = 0\n",
    "            Q[s][a] = Q[s][a] + lr*(r + g*Q[tuple(eat)][0] - Q[s][a])\n",
    "            policy.update_with_Q(s,Q[s])\n",
    "            r = 0\n",
    "            s = tuple(game.get_state())\n",
    "            a = policy[s]\n",
    "        else:\n",
    "            # next state and next action\n",
    "            s_p = tuple(game.get_state())\n",
    "            a_p = policy[s_p]\n",
    "            # update Q\n",
    "            if (s_p not in Q):\n",
    "                Q[s_p] = {}\n",
    "            if (a_p not in Q[s_p]):\n",
    "                Q[s_p][a_p] = 0\n",
    "            Q[s][a] = Q[s][a] + lr*(r + g*Q[s_p][a_p] - Q[s][a])\n",
    "            # update policy for this state\n",
    "            policy.update_with_Q(s,Q[s])\n",
    "            # update variables for next iteration\n",
    "            s = s_p\n",
    "            a = a_p           \n",
    "    # print progress\n",
    "    if (i%1000==0):\n",
    "        print(i,turns,score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the policy without epsilon greedy\n",
    "p = dict(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAACfVJREFUeJzt3d+LHfUdxvHnaVRafyE0aZEkdhUkIIUaWQISEBrbEqtoL3qRgEKlkCtFaUG0d/0HxF4UQaJWMFXaqCBitYKKFVrrJqY/4saShpRso82GIv4oNESfXuxJSWPKmc2Z2Zn95P2CJXvODrufw/LOzJk9Z75OIgA1fa7vAQB0h8CBwggcKIzAgcIIHCiMwIHCCBwojMCBwggcKOycLr7pypUrMzU11cW3BiDp4MGDOnr0qMdt10ngU1NTmpmZ6eJbA5A0PT3daDsO0YHCCBwojMCBwggcKIzAgcIIHCiMwIHCCBworFHgtjfbfsf2ftv3dj0UgHaMDdz2Ckk/lXSDpKskbbV9VdeDAZhckz34Bkn7kxxIckzSk5Ju6XYsAG1oEvhqSYdOuj03ug/AwDUJ/HTvWPnMxdRtb7M9Y3tmfn5+8skATKxJ4HOS1p50e42kw6dulOShJNNJpletWtXWfAAm0CTwNyVdafty2+dJ2iLp2W7HAtCGse8HT3Lc9h2SXpS0QtIjSfZ2PhmAiTW64EOS5yU93/EsAFrGK9mAwggcKIzAgcIIHCiMwIHCCBwojMCBwggcKKyTlU2qsseuFIOzXPKZ92H1ij04UBiBA4UROFAYgQOFEThQGIEDhRE4UBiBA4UROFBYk5VNHrF9xPafl2IgAO1psgf/maTNHc8BoANjA0/ymqR/LsEsAFrGc3CgsNYCZ+kiYHhaC5yli4Dh4RAdKKzJn8mekPRbSetsz9n+fvdjAWhDk7XJti7FIADaxyE6UBiBA4UROFAYgQOFEThQGIEDhRE4UBiBA4WxdNEiDG1ZGox3ti83xR4cKIzAgcIIHCiMwIHCCBwojMCBwggcKIzAgcIIHCiMwIHCmlx0ca3tV2zP2t5r+66lGAzA5Jq8Fv24pB8m2W37Ikm7bL+U5O2OZwMwoSZrk72bZPfo8w8lzUpa3fVgACa3qOfgtqckrZf0xmm+xtJFwMA0Dtz2hZKeknR3kg9O/TpLFwHD0yhw2+dqIe4dSZ7udiQAbWlyFt2SHpY0m+T+7kcC0JYme/CNkm6TtMn2ntHHtzueC0ALmqxN9rqks/u6N8AyxSvZgMIIHCiMwIHCCBwojMCBwggcKIzAgcIIHCiMwIHCCBwojMCBwggcKIzAgcIIHCiMwIHCCBwojMCBwggcKKzJRRc/b/v3tv8wWrrox0sxGIDJNVm66N+SNiX5aHT55Ndt/yrJ7zqeDcCEmlx0MZI+Gt08d/SRLocC0I6mCx+ssL1H0hFJLyVh6SJgGWgUeJJPklwtaY2kDba/epptWLoIGJhFnUVP8r6kVyVt7mQaAK1qchZ9le1LRp9/QdI3JO3rejAAk2tyFv1SSY/ZXqGF/xB+keS5bscC0IYmZ9H/qIU1wQEsM7ySDSiMwIHCCBwojMCBwggcKIzAgcIIHCiMwIHCCBwojMCBwggcKIzAgcIIHCiMwIHCCBwojMCBwggcKIzAgcIaBz66NvpbtrkeG7BMLGYPfpek2a4GAdC+piubrJF0o6Tt3Y4DoE1N9+APSLpH0qcdzgKgZU0WPrhJ0pEku8Zsx9pkwMA02YNvlHSz7YOSnpS0yfbjp27E2mTA8IwNPMl9SdYkmZK0RdLLSW7tfDIAE+Pv4EBhTdYm+68kr2phdVEAywB7cKAwAgcKI3CgMAIHCiNwoDACBwojcKAwAgcKI3CgMAIHCiNwoDACBwojcKAwAgcKI3CgMAIHCiNwoDACBwprdMmm0RVVP5T0iaTjSaa7HApAOxZzTbavJzna2SQAWschOlBY08Aj6de2d9ne1uVAANrT9BB9Y5LDtr8k6SXb+5K8dvIGo/C3SdJll13W8pgAzkSjPXiSw6N/j0h6RtKG02zD0kXAwDRZfPAC2xed+FzStyT9uevBAEyuySH6lyU9Y/vE9j9P8kKnUwFoxdjAkxyQ9LUlmAVAy/gzGVAYgQOFEThQGIEDhRE4UBiBA4UROFAYgQOFEThQGIEDhRE4UBiBA4UROFAYgQOFEThQGIEDhRE4UBiBA4U1Ctz2JbZ32t5ne9b2tV0PBmByTa+L/hNJLyT5ru3zJJ3f4UwAWjI2cNsXS7pO0vckKckxSce6HQtAG5ocol8haV7So7bfsr19dH10AAPXJPBzJF0j6cEk6yV9LOneUzeyvc32jO2Z+fn5lscEcCaaBD4naS7JG6PbO7UQ/P9g6SJgeMYGnuQ9SYdsrxvddb2ktzudCkArmp5Fv1PSjtEZ9AOSbu9uJABtaRR4kj2SpjueBUDLeCUbUBiBA4UROFAYgQOFEThQGIEDhRE4UBiBA4UROFBY05eqDpe9dD8rWbqfVZiX8nd2lmMPDhRG4EBhBA4URuBAYQQOFEbgQGEEDhRG4EBhBA4UNjZw2+ts7znp4wPbdy/FcAAmM/alqknekXS1JNleIenvkp7peC4ALVjsIfr1kv6a5G9dDAOgXYsNfIukJ073BZYuAoanceCjRQ9ulvTL032dpYuA4VnMHvwGSbuT/KOrYQC0azGBb9X/OTwHMEyNArd9vqRvSnq623EAtKnp2mT/kvTFjmcB0DJeyQYURuBAYQQOFEbgQGEEDhRG4EBhBA4URuBAYU4Hy/HYnpe02LeUrpR0tPVhhqHqY+Nx9ecrSca+q6uTwM+E7Zkk033P0YWqj43HNXwcogOFEThQ2JACf6jvATpU9bHxuAZuMM/BAbRvSHtwAC0bROC2N9t+x/Z+2/f2PU8bbK+1/YrtWdt7bd/V90xtsr3C9lu2n+t7ljbZvsT2Ttv7Rr+7a/ueaRK9H6KPrrX+Fy1cMWZO0puStiZ5u9fBJmT7UkmXJtlt+yJJuyR9Z7k/rhNs/0DStKSLk9zU9zxtsf2YpN8k2T660Oj5Sd7ve64zNYQ9+AZJ+5McSHJM0pOSbul5pokleTfJ7tHnH0qalbS636naYXuNpBslbe97ljbZvljSdZIelqQkx5Zz3NIwAl8t6dBJt+dUJIQTbE9JWi/pjX4nac0Dku6R9Gnfg7TsCknzkh4dPf3YbvuCvoeaxBAC92nuK3Nq3/aFkp6SdHeSD/qeZ1K2b5J0JMmuvmfpwDmSrpH0YJL1kj6WtKzPCQ0h8DlJa0+6vUbS4Z5maZXtc7UQ944kVa5Iu1HSzbYPauHp1Cbbj/c7UmvmJM0lOXGktVMLwS9bQwj8TUlX2r58dFJji6Rne55pYrathedys0nu73uetiS5L8maJFNa+F29nOTWnsdqRZL3JB2yvW501/WSlvVJ0UaXTe5SkuO275D0oqQVkh5JsrfnsdqwUdJtkv5ke8/ovh8leb7HmTDenZJ2jHY2ByTd3vM8E+n9z2QAujOEQ3QAHSFwoDACBwojcKAwAgcKI3CgMAIHCiNwoLD/AGoIds3CLTLUAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# render a game animation\n",
    "fig, ax = plt.subplots()\n",
    "image = ax.imshow(game.board)\n",
    "\n",
    "g = Game(grid, s_size)\n",
    "g.reset()\n",
    "\n",
    "def init():\n",
    "    image.set_data(g.board)\n",
    "    return (image,)\n",
    "\n",
    "def animate(i):\n",
    "    s = g.get_state()\n",
    "    a = p[tuple(s)]\n",
    "    g.snake.d = a\n",
    "    g.iterate() \n",
    "    g.draw()\n",
    "    image.set_data(g.board)\n",
    "    return (image,)\n",
    "\n",
    "anim = animation.FuncAnimation(fig, animate, init_func=init,\n",
    "                               frames=300, interval=120, \n",
    "                               blit=True)\n",
    "\n",
    "anim.save('./animations/sarsa.gif', writer='imagemagick', fps=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"./animations/sarsa.gif\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url='./animations/sarsa.gif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
